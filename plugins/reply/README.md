# QQ机器人回复插件使用指南

## 概述

`reply` 插件是QQ机器人的核心回复处理插件，支持两种回复策略：
- **命令模式** (CmdStrategy): 只响应以指定前缀开头的命令
- **LLM模式** (LlmStrategy): 使用大语言模型进行智能聊天，同时保留命令功能

## 主要改进

### 1. 统一的回复管理
- 使用 `ReplyManager` 统一处理所有回复策略
- 自动根据用户设置选择合适的处理方式
- 智能的消息路由和错误处理

### 2. 增强的消息处理
- 支持群聊和私聊消息
- LLM模式下自动响应所有文本消息
- 命令模式下只响应命令消息
- 友好的错误消息提示

### 3. 灵活的策略切换
- 用户可通过 `/strategy` 命令切换回复模式
- 实时生效，无需重启机器人
- 管理员权限控制

## 使用方法

### 切换到LLM模式
```
/strategy llm
```
在LLM模式下：
- 普通聊天消息会由大模型处理
- 命令消息仍然正常执行
- 群聊和私聊都支持

### 切换到命令模式
```
/strategy cmd
```
在命令模式下：
- 只响应以命令前缀开头的消息
- 普通聊天消息不会被处理

### 其他可用命令
```
/query grade          # 查询成绩
/bind 123456          # 绑定学号
/strategy llm         # 切换到LLM模式
```

## 配置说明

### LLM配置 (config.dev.toml)
```toml
[llm]
api_key = "your-siliconflow-api-key"
base_url = "https://api.siliconflow.cn/v1"
model = "deepseek-chat"
system_prompt = "你是一个友好的QQ机器人助手，请用简洁、有用的方式回复用户的问题。"
temperature = 0.7
max_tokens = 2048
top_p = 0.95
timeout_seconds = 30
```

### 命令前缀配置
```toml
cmd_suffix = "/"      # 命令前缀
```

### 管理员配置
```toml
admins = [123456789]  # 管理员QQ号列表
```

## 错误处理

插件会自动处理各种错误情况：

1. **API服务不可用**: "抱歉，AI服务暂时不可用，请稍后再试。"
2. **命令执行失败**: "命令执行失败，请检查命令格式。"
3. **其他错误**: 显示具体错误信息

## 技术特性

- **异步处理**: 所有操作都是异步的，不会阻塞机器人
- **内存缓存**: 用户策略设置保存在高性能内存缓存中
- **克隆优化**: 支持多线程环境下的安全克隆
- **智能路由**: 根据消息类型和用户设置自动选择处理策略

## 部署

1. 确保在工作空间根目录的 `Cargo.toml` 中包含：
   ```toml
   members = ["plugins/reply", ...]
   ```

2. 在 `qqbot-cmd/Cargo.toml` 中添加依赖：
   ```toml
   reply = { path = "../plugins/reply" }
   ```

3. 在 `qqbot-cmd/src/main.rs` 中注册插件：
   ```rust
   build_bot!(reply, apply_request, kovi_plugin_siliconflow).run();
   ```

## 示例对话

### LLM模式示例
```
用户: 你好
机器人: 你好！我是QQ机器人助手，有什么可以帮助你的吗？

用户: 今天天气怎么样？
机器人: 抱歉，我无法获取实时天气信息。建议你查看天气应用或询问"今天天气"相关的命令。

用户: /strategy cmd
机器人: 已成功切换到命令模式！
```

### 命令模式示例
```
用户: 你好
(无回复，因为不是命令)

用户: /query grade
机器人: [查询结果...]

用户: /strategy llm
机器人: 已成功切换到大模型聊天模式！
```

这个更新显著提升了机器人的用户体验和功能灵活性！
